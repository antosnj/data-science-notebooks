{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "*  [Introduction](#section1) \n",
    "*  [Import libraries](#section2) \n",
    "*  [EDA](#section3) \n",
    "    *  [Read the data in](#section4)\n",
    "    *  [Data Exploration](#section5)\n",
    "        - [Target column](#section6)\n",
    "    *  [Cleaning](#section7)\n",
    "        - [Irrelevant & Reduntant columns](#section8)\n",
    "        - [Data leakage - Features that inject future knowledge](#section9)\n",
    "        - [Columns with only one unique value](#section10)  \n",
    "        - [Missing values](#section11)  \n",
    "*  [Feature Engineering](#section12)\n",
    "    *  [Data pre-processing: Categorical columns](#section13)\n",
    "*  [Modeling and testing](#section14)\n",
    "    *  [Class Imbalance](#section15)\n",
    "    *  [Error Metric](#section16)\n",
    "    *  [Logistic Regression Model - Cross Validation](#section17)  \n",
    "    *  [Random Forests](#section18)  \n",
    "    *  [Ensembled model: LightGBM + XGBoost](#section19)\n",
    "        - [LightGBM](#section20)\n",
    "        - [XGBoost](#section21)\n",
    "        - [Ensemble](#section30)\n",
    "*  [Feature Importance](#section22)\n",
    "*  [Conclusions](#section23)\n",
    "    \n",
    "by @samaxtech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section1'></a>\n",
    "# Introduction\n",
    "This project aims to build different machine learning models to model credit risk, by classifing borrowers and predict whether they will pay off their loan on time or not, as a binary classification problem. The data consists on approved loans data from 2007 to 2011 from Lending Club (https://www.lendingclub.com/), a marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section2'></a>\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sama/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section3'></a>\n",
    "# EDA\n",
    "<a id='section4'></a>\n",
    "## Read the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42538, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade    ...    last_pymnt_amnt  \\\n",
       "0   10.65%       162.87     B        B2    ...             171.62   \n",
       "1   15.27%        59.83     C        C4    ...             119.66   \n",
       "2   15.96%        84.33     C        C5    ...             649.91   \n",
       "3   13.49%       339.31     C        C1    ...             357.48   \n",
       "4   12.69%        67.79     B        B5    ...              67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
       "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "1           Sep-2013                        0.0          1.0       INDIVIDUAL   \n",
       "2           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "3           Apr-2016                        0.0          1.0       INDIVIDUAL   \n",
       "4           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "\n",
       "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
       "0            0.0                      0.0         0.0                  0.0   \n",
       "1            0.0                      0.0         0.0                  0.0   \n",
       "2            0.0                      0.0         0.0                  0.0   \n",
       "3            0.0                      0.0         0.0                  0.0   \n",
       "4            0.0                      0.0         0.0                  0.0   \n",
       "\n",
       "  tax_liens  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv('loans_2007.csv', low_memory=False)\n",
    "\n",
    "print(loans_2007.shape)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section5'></a>\n",
    "## Data Exploration\n",
    "<a id='section6'></a>\n",
    "### Target column\n",
    "Firstly, let's study the **'loan_status'** column. This will be, after some processing, the target column since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_loan_status = loans_2007['loan_status'].value_counts() \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "freq_loan_status.plot(kind='barh',alpha=0.75, rot=0, colormap=plt.cm.Accent)\n",
    "\n",
    "plt.title('Loan Status History, 2007-2011', size=20)\n",
    "plt.xlabel('# of Borrowers', size=12)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.tick_params(top=\"off\", left=\"off\", right=\"off\", bottom='off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation for each status as well as the counts in the loans_2007 Dataframe is:\n",
    "\n",
    "- **Fully Paid (33136):** Loan has been fully paid off.\n",
    "- **Charged Off (5634):** Loan for which there is no longer a reasonable expectation of further payments.\n",
    "- **Does not meet the credit policy. Status - Fully Paid (1988):** While the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "- **Does not meet the credit policy. Status - Charged Off (761):** While the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "- **In Grace Period\t(20):** The loan is past due but still in the grace period of 15 days.\n",
    "- **Late (16-30 days) (8):** Loan hasn't been paid in 16 to 30 days (late on the current payment).\n",
    "- **Late (31-120 days) (24):** Loan hasn't been paid in 31 to 120 days (late on the current payment).\n",
    "- **Current\t(961):** Loan is up to date on current payments.\n",
    "- **Default\t(3):** Loan is defaulted on and no payment has been made for more than 121 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Since we're interested in being able to predict which of these 2 values a loan will fall under:\n",
    "- Fully Paid **(1)**\n",
    "- Charged Off **(0)**\n",
    "\n",
    "We can treat the problem as a **binary classification** one. Let's remove all the loans that don't contain either Fully Paid or Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "Shape after target col processing\n",
      "----------------------------------\n",
      " (38770, 52)\n"
     ]
    }
   ],
   "source": [
    "# Remove loans that don't contain either Fully Paid or Charged Off\n",
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == 'Fully Paid') | (loans_2007['loan_status'] == 'Charged Off')]\n",
    "\n",
    "\n",
    "# Map Fully Paid/Charged Off to 0/1\n",
    "mapping_dict = {\n",
    "    'loan_status':{\n",
    "        'Fully Paid':1,\n",
    "        'Charged Off':0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007.replace(mapping_dict, inplace=True)\n",
    "\n",
    "print(\"\\n----------------------------------\\nShape after target col processing\\n----------------------------------\\n\", loans_2007.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should also be pointed out that there is a class imbalance between Fully Paid and Charged Off, given the difference in the amount of values between both. That will be tackled later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section7'></a>\n",
    "## Cleaning\n",
    "Let's focus on columns that:\n",
    "\n",
    "1. Leak information from the future (after the loan has already been funded).\n",
    "2. Don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club).\n",
    "3. Formatted poorly and need to be cleaned up.\n",
    "4. Require more data or a lot of processing to turn into a useful feature.\n",
    "5. Contain redundant information.\n",
    "6. Only contain one value, since they don't add any information to each loan application and won't be useful for the model.\n",
    "\n",
    "---\n",
    "<a id='section8'></a>\n",
    "### Irrelevant & Reduntant columns\n",
    "In order not to take into account columns that don't affect a borrower's ability to pay back a loan and contain redundant information, the following features need to be removed:\n",
    "\n",
    "- **id:** randomly generated field by Lending Club for unique identification purposes only\n",
    "- **member_id:** also a randomly generated field by Lending Club for unique identification purposes only\n",
    "- **funded_amnt:** leaks data from the future (after the loan has already started to be funded)\n",
    "- **funded_amnt_inv:** also leaks data from the future (after the loan has already started to be funded)\n",
    "- **grade:** contains redundant information as the interest rate column ('int_rate', which contains continuous values, which are better suited for machine learning). \n",
    "- **sub_grade:** also contains redundant information as the interest rate column.\n",
    "- **emp_title:** requires other data and a lot of processing to potentially be useful\n",
    "- **issue_d:** leaks data from the future (after the loan is already completed funded)\n",
    "- **zip_code:** redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop_1 = ['id', 'member_id', 'funded_amnt', 'funded_amnt_inv', 'grade', \n",
    "               'sub_grade', 'emp_title', 'issue_d', 'zip_code']\n",
    "\n",
    "loans_2007.drop(cols_drop_1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section9'></a>\n",
    "### Data leakage - Features that inject future knowledge\n",
    "To prevent our model from overfitting and using data about the target column that wouldn't be available when we're using the model on future loans, the following features need to be removed:\n",
    "\n",
    "- **out_prncp:** leaks data from the future, (after the loan already started to be paid off)\n",
    "- **out_prncp_inv:** also leaks data from the future.\n",
    "- **total_pymnt:** also leaks data from the future.\n",
    "- **total_pymnt_inv:** also leaks data from the future.\n",
    "- **total_rec_prncp:** also leaks data from the future.\n",
    "- **total_rec_int:** leaks data from the future.\n",
    "- **total_rec_late_fee:** also leaks data from the future.\n",
    "- **recoveries:** also leaks data from the future.\n",
    "- **collection_recovery_fee:** also leaks data from the future.\n",
    "- **last_pymnt_d:** also leaks data from the future.\n",
    "- **last_pymnt_amnt:** also leaks data from the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "Shape after dropping cols\n",
      "--------------------------\n",
      " (38770, 32)\n"
     ]
    }
   ],
   "source": [
    "cols_drop_2 = ['out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
    "              'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
    "              'last_pymnt_d', 'last_pymnt_amnt']\n",
    "\n",
    "loans_2007.drop(cols_drop_2, axis=1, inplace=True)\n",
    "print(\"\\n--------------------------\\nShape after dropping cols\\n--------------------------\\n\", loans_2007.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section10'></a>\n",
    "### Columns with only one unique value\n",
    "To check the number of unique values on each column and drop those with only one, let's use the following approach:\n",
    "\n",
    "For each column:\n",
    "- Drop any null values.\n",
    "- Check the number of unique values.\n",
    "- Remove the col if the previous number is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Columns with only one unique value\n",
      "-----------------------------------\n",
      "pymnt_plan\n",
      "initial_list_status\n",
      "collections_12_mths_ex_med\n",
      "policy_code\n",
      "application_type\n",
      "acc_now_delinq\n",
      "chargeoff_within_12_mths\n",
      "delinq_amnt\n",
      "tax_liens\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------------\\nColumns with only one unique value\\n-----------------------------------\")\n",
    "      \n",
    "for col in loans_2007.columns:\n",
    "    # Drop any null values\n",
    "    non_null = loans_2007[col].dropna()\n",
    "    \n",
    "    # Check the number of unique values\n",
    "    unique_non_null = non_null.unique()\n",
    "    num_true_unique = len(unique_non_null)\n",
    "    \n",
    "    # Remove the col if there is only 1 unique value\n",
    "    if num_true_unique == 1:\n",
    "        loans_2007.drop(col, axis=1, inplace=True)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section11'></a>\n",
    "### Missing values\n",
    "Let's remove any columns with more than 1% of missing values, keeping 'emp_length', since it contains the number of years the borrower was employed upon time of application, which is likely to be useful for the model given what we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Percentage of missing values (%):\n",
      "-----------------------------------\n",
      " loan_amnt               0.000000\n",
      "term                    0.000000\n",
      "int_rate                0.000000\n",
      "installment             0.000000\n",
      "emp_length              2.672169\n",
      "home_ownership          0.000000\n",
      "annual_inc              0.000000\n",
      "verification_status     0.000000\n",
      "loan_status             0.000000\n",
      "purpose                 0.000000\n",
      "title                   0.028372\n",
      "addr_state              0.000000\n",
      "dti                     0.000000\n",
      "delinq_2yrs             0.000000\n",
      "earliest_cr_line        0.000000\n",
      "inq_last_6mths          0.000000\n",
      "open_acc                0.000000\n",
      "pub_rec                 0.000000\n",
      "revol_bal               0.000000\n",
      "revol_util              0.128966\n",
      "total_acc               0.000000\n",
      "last_credit_pull_d      0.005159\n",
      "pub_rec_bankruptcies    1.797782\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_values = loans_2007.isnull().sum()\n",
    "print(\"\\n-----------------------------------\\nPercentage of missing values (%):\\n-----------------------------------\\n\", null_values*100 / len(loans_2007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_1pct = ['pub_rec_bankruptcies']\n",
    "loans_2007.drop(more_than_1pct, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after dropping those columns let's remove any remaining rows that contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "Shape after cleaning\n",
      "----------------------\n",
      " (37675, 22)\n"
     ]
    }
   ],
   "source": [
    "loans_2007.dropna(inplace=True)\n",
    "print(\"\\n----------------------\\nShape after cleaning\\n----------------------\\n\", loans_2007.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section12'></a>\n",
    "# Feature Engineering\n",
    "<a id='section13'></a>\n",
    "## Data pre-processing: Categorical columns\n",
    "Let's see how many columns have object type, and check the number of unique values for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "Object columns\n",
      "----------------------\n",
      "['term', 'int_rate', 'emp_length', 'home_ownership', 'verification_status', 'purpose', 'title', 'addr_state', 'earliest_cr_line', 'revol_util', 'last_credit_pull_d']\n"
     ]
    }
   ],
   "source": [
    "object_cols = list(loans_2007.select_dtypes(include=['object']).columns)\n",
    "print(\"\\n----------------------\\nObject columns\\n----------------------\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "Unique values in object cols\n",
      "-----------------------------\n",
      "term : 2\n",
      "int_rate : 371\n",
      "emp_length : 11\n",
      "home_ownership : 5\n",
      "verification_status : 3\n",
      "purpose : 14\n",
      "title : 18881\n",
      "addr_state : 50\n",
      "earliest_cr_line : 514\n",
      "revol_util : 1086\n",
      "last_credit_pull_d : 107\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------\\nUnique values in object cols\\n-----------------------------\")\n",
    "for col in object_cols:\n",
    "    print(col, \":\", len(loans_2007[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The resulting columns include:\n",
    "\n",
    "- **home_ownership:** home ownership status, can only be 1 of 4 categorical values according to the data dictionary.\n",
    "- **verification_status:** indicates if income was verified by Lending Club.\n",
    "- **emp_length:** number of years the borrower was employed upon time of application.\n",
    "- **term:** number of payments on the loan, either 36 or 60.\n",
    "- **addr_state:** borrower's state of residence.\n",
    "- **purpose:** a category provided by the borrower for the loan request.\n",
    "- **title:** loan title provided the borrower.\n",
    "\n",
    "In addition, there are two columns that represent numeric values, that need to be converted:\n",
    "\n",
    "- **int_rate:** interest rate of the loan in %,\n",
    "- **revol_util:** revolving line utilization rate or the amount of credit the borrower is using relative to all available credit, read more here.\n",
    "\n",
    "Lastly, the following columns would need a solid feature engineering to be useful for the model. \n",
    "\n",
    "- **earliest_cr_line:** The month the borrower's earliest reported credit line was opened,\n",
    "- **last_credit_pull_d:** The most recent month Lending Club pulled credit for this loan.\n",
    "\n",
    "---\n",
    "For performance purposes, let's start by removing 'addr_state', and 'title', since they contain too many discrete values and we'd need to add too many dummy variable columns to use them for classification. Also, let's convert 'earliest_cr_line' and 'last_credit_pull_d' to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['addr_state', 'title']\n",
    "loans_2007.drop(cols_drop, axis=1, inplace=True)\n",
    "\n",
    "for col in ['last_credit_pull_d', 'earliest_cr_line']:\n",
    "    loans_2007.loc[:, col] = pd.DatetimeIndex(loans_2007[col]).astype(np.int64)*1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's convert 'int_rate' and 'revol_util' to float columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_rate</th>\n",
       "      <th>revol_util</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.65</td>\n",
       "      <td>83.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.27</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.96</td>\n",
       "      <td>98.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.49</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.90</td>\n",
       "      <td>28.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   int_rate  revol_util\n",
       "0     10.65        83.7\n",
       "1     15.27         9.4\n",
       "2     15.96        98.5\n",
       "3     13.49        21.0\n",
       "5      7.90        28.3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols = ['int_rate', 'revol_util']\n",
    "for col in float_cols:\n",
    "    loans_2007[col] = loans_2007[col].str.rstrip('%').astype(float)\n",
    "    \n",
    "loans_2007[float_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean the 'emp_length' column, we can use the following mapping:\n",
    "\n",
    "- \"10+ years\": 10\n",
    "- \"9 years\": 9\n",
    "- \"8 years\": 8\n",
    "- \"7 years\": 7\n",
    "- \"6 years\": 6\n",
    "- \"5 years\": 5\n",
    "- \"4 years\": 4\n",
    "- \"3 years\": 3\n",
    "- \"2 years\": 2\n",
    "- \"1 year\": 1\n",
    "- \"< 1 year\": 0\n",
    "- \"n/a\": 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    'emp_length': {\n",
    "        '10+ years': 10,\n",
    "        '9 years': 9,\n",
    "        '8 years': 8,\n",
    "        '7 years': 7,\n",
    "        '6 years': 6,\n",
    "        '5 years': 5,\n",
    "        '4 years': 4,\n",
    "        '3 years': 3,\n",
    "        '2 years': 2,\n",
    "        '1 year': 1,\n",
    "        '< 1 year': 0,\n",
    "        'n/a': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007.replace(mapping_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's encode 'home_ownership', 'verification_status', 'term', and 'purpose' as dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['home_ownership', 'verification_status', 'term', 'purpose']\n",
    "\n",
    "for col in dummy_cols:\n",
    "    dummy_df = pd.get_dummies(loans_2007[col])\n",
    "    loans_2007 = pd.concat([loans_2007, dummy_df], axis=1)\n",
    "    loans_2007.drop(col, axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's take a look at how the 'loans_2007' Dataframe looks like after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "Shape after pre-processing\n",
      "----------------------------------\n",
      " (37675, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>home_improvement</th>\n",
       "      <th>house</th>\n",
       "      <th>major_purchase</th>\n",
       "      <th>medical</th>\n",
       "      <th>moving</th>\n",
       "      <th>other</th>\n",
       "      <th>renewable_energy</th>\n",
       "      <th>small_business</th>\n",
       "      <th>vacation</th>\n",
       "      <th>wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.733856e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.229248e+08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>10</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004573e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.231328e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>3</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099267e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  emp_length  annual_inc  loan_status  \\\n",
       "0     5000.0     10.65       162.87          10     24000.0            1   \n",
       "1     2500.0     15.27        59.83           0     30000.0            0   \n",
       "2     2400.0     15.96        84.33          10     12252.0            1   \n",
       "3    10000.0     13.49       339.31          10     49200.0            1   \n",
       "5     5000.0      7.90       156.46           3     36000.0            1   \n",
       "\n",
       "     dti  delinq_2yrs  earliest_cr_line  inq_last_6mths   ...     \\\n",
       "0  27.65          0.0      4.733856e+08             1.0   ...      \n",
       "1   1.00          0.0      9.229248e+08             5.0   ...      \n",
       "2   8.72          0.0      1.004573e+09             2.0   ...      \n",
       "3  20.00          0.0      8.231328e+08             1.0   ...      \n",
       "5  11.20          0.0      1.099267e+09             3.0   ...      \n",
       "\n",
       "   home_improvement  house  major_purchase  medical  moving  other  \\\n",
       "0                 0      0               0        0       0      0   \n",
       "1                 0      0               0        0       0      0   \n",
       "2                 0      0               0        0       0      0   \n",
       "3                 0      0               0        0       0      1   \n",
       "5                 0      0               0        0       0      0   \n",
       "\n",
       "   renewable_energy  small_business  vacation  wedding  \n",
       "0                 0               0         0        0  \n",
       "1                 0               0         0        0  \n",
       "2                 0               1         0        0  \n",
       "3                 0               0         0        0  \n",
       "5                 0               0         0        1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n----------------------------------\\nShape after pre-processing\\n----------------------------------\\n\", loans_2007.shape)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section14'></a>\n",
    "# Modeling and Testing\n",
    "<a id='section15'></a>\n",
    "## Class Imbalance\n",
    "As I mentioned earlier, there are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0) in the dataset. This means even if the classifier predicted all ones (all loans will be paid off on time, which would make us lose money for a decent amount of cases, the model would still have a high accuracy).\n",
    "\n",
    "As an example, if there were 6 loans that were paid off on time and 1 that wasn't, if our model predicted all ones that'd mean that investing 1000 dollars with a 10 percent interest on each one would lose us $400 overall.\n",
    "\n",
    "- **(<font color='green'>100</font>x6) - (<font color='red'>1000</font>x1) = <font color='red'>-400</font> dollars**\n",
    "\n",
    "That's why using accuracy for this particular dataset is not a good idea. Instead, we can compute the True Positive Rate (TPR) (high recall) and False Positive Rate (FPR) (low fall-out).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section16'></a>\n",
    "## Error Metric\n",
    "Following what I mentioned in the 'Class Imbalance' section, our objective is to predict whether or not we should fund a loan based on whether a borrower will pay off their loan on time or not. Since the ultimate objective is to make money, ideally we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. \n",
    "\n",
    "From an investor perspective, we want to pay attention to:\n",
    "\n",
    "- **False Positives (FP):** the model predicts a loan will be paid off on time, but it actually isn't.\n",
    "- **False Negatives (FN):** the model predicts a loan will not be paid off on time, but it actually is.\n",
    "\n",
    "False Positives (FP) will cost us money, and False Negatives (FN) will lose us potential money. From the perspective of a conservative investor and to minimize risk, we need to avoid false positives as much as possible, since losing actual money by funding a risky loan (false positives) would be worse than losing potential money by missing out on opportunities (false negatives).\n",
    "\n",
    "To sum it up, the error metric will be based on:\n",
    "\n",
    "| loan_status (Actual) | Prediction   |     Error Type     |\n",
    "|----------------------|--------------|--------------------|\n",
    "|          0           |       1      | False Positive (FP)\n",
    "|          1           |       1      | True Positive (TP)\n",
    "|          0           |       0      | True Negative (TN)\n",
    "|          1           |       0      | False Negative (FN)\n",
    "\n",
    "So that we can compute the True Positive Rate (TPR) and False Positive Rate (FPR), as follows:\n",
    "\n",
    "- **FPR = FP / (FP + TN)**, which divides all the cases where we thought a loan would be paid off but it wasn't by all the loans that weren't paid off (what percentage of the loans that I fund would not be repaid).\n",
    "- **TPR = TP / (TP + FN)**, which divides all the cases where we thought a loan would be paid off and it was by all the loans that were paid off (what percentage of loans that could be funded would I fund).\n",
    "\n",
    "Let's create a function to calculate FPR and TPR from the actual and predicted values of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_fpr(actual, predicted):\n",
    "    # FP\n",
    "    fp_filter = (actual == 0) & (predicted == 1)\n",
    "    fp = len(predicted[fp_filter])\n",
    "    \n",
    "    # TP\n",
    "    tp_filter = (actual == 1) & (predicted == 1) \n",
    "    tp = len(predicted[tp_filter])\n",
    "\n",
    "    # TN\n",
    "    tn_filter = (actual == 0) & (predicted == 0)\n",
    "    tn = len(predicted[tn_filter])\n",
    "    \n",
    "    # FN\n",
    "    fn_filter = (actual == 1) &(predicted == 0)\n",
    "    fn = len(predicted[fn_filter])\n",
    "\n",
    "    tpr = tp  / (tp + fn)\n",
    "    fpr = fp  / (fp + tn)\n",
    "    \n",
    "    return(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section17'></a>\n",
    "## Logistic Regression Model - Cross Validation\n",
    "Let's start out by testing a logistic regression model performance by using a 3-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "Logistic Regression\n",
      "----------------------------------\n",
      "FPR: 1.0\n",
      "TPR: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "target = 'loan_status'\n",
    "X_train = loans_2007.loc[:, loans_2007.columns != target]\n",
    "y_train = loans_2007[target]\n",
    "\n",
    "# LR Model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train\n",
    "predictions_lr = cross_val_predict(lr, X_train, y_train, cv=3)\n",
    "predictions_lr = pd.Series(predictions_lr)\n",
    "\n",
    "# Test performance - FPR and TPR\n",
    "fpr_lr, tpr_lr = tpr_fpr(y_train, predictions_lr)\n",
    "\n",
    "print(\"\\n----------------------------------\\nLogistic Regression\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_lr)\n",
    "print(\"TPR:\", tpr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the FPR and TPR are around what we'd expect if the model was predicting all ones. This is because even though we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes.\n",
    "\n",
    "In order to solve that, we can either:\n",
    "\n",
    "1. Use oversampling and undersampling to ensure that the classifier gets input that has a balanced number of each class.\n",
    "2. Tell the classifier to penalize misclassifications of the less prevalent class more than the other class.\n",
    "\n",
    "For the purpose of this project and because of the ease of implementation in scikit-learn, I will use the second method. To do so, let's change the 'class_weight' parameter in the LogisticRegression instance, which will penalize the misclassification of the minority class (0) during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "Logistic Regression\n",
      "----------------------------------\n",
      "FPR: 0.09753208292201382\n",
      "TPR: 0.1013371788148925\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 7,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "# LR Model\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "\n",
    "# Train\n",
    "predictions_lr = cross_val_predict(lr, X_train, y_train, cv=3)\n",
    "predictions_lr = pd.Series(predictions_lr)\n",
    "\n",
    "# Test performance - FPR and TPR\n",
    "fpr_lr, tpr_lr = tpr_fpr(y_train, predictions_lr)\n",
    "\n",
    "print(\"\\n----------------------------------\\nLogistic Regression\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_lr)\n",
    "print(\"TPR:\", tpr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the FPR fell to around 9%. While this means that an investor will be able to do a better job at avoiding bad loans than if he/she funded everything, the TPR also fell to around 10%, which means that same investor will decide to fund only 10% of the total loans that are going to be paid off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section18'></a>\n",
    "## Random Forests\n",
    "Let's test a random forest model with a higher class weight penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "Random Forests\n",
      "----------------------------------\n",
      "FPR: 0.9569595261599211\n",
      "TPR: 0.9542475091767174\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "# RF Model\n",
    "rf = RandomForestClassifier(class_weight=penalty, random_state=1)\n",
    "\n",
    "# Train\n",
    "predictions_rf = cross_val_predict(rf, X_train, y_train, cv=3)\n",
    "predictions_rf = pd.Series(predictions_rf)\n",
    "\n",
    "# Test performance - FPR and TPR\n",
    "fpr_rf, tpr_rf = tpr_fpr(y_train, predictions_rf)\n",
    "\n",
    "print(\"\\n----------------------------------\\nRandom Forests\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_rf)\n",
    "print(\"TPR:\", tpr_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the TPR went up again, it looks like the model is likely weighting too heavily on the 1 class, and still mostly predicting ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section19'></a>\n",
    "## Ensembled model: LightGBM + XGBoost\n",
    "Lastly, let's test LightGBM and XGBoost on an ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Shapes:\n",
      "------------------------------------------------\n",
      "(25242, 39) (12433, 39) (25242,) (12433,)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "X = loans_2007.loc[:, loans_2007.columns != target]\n",
    "y = loans_2007[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(\"------------------------------------------------\\nShapes:\\n------------------------------------------------\")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section20'></a>\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB 0--------------------------------------------------\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\ttraining's rmse: 0.319349\tvalid_1's rmse: 0.324839\n",
      "[400]\ttraining's rmse: 0.307207\tvalid_1's rmse: 0.32128\n",
      "[600]\ttraining's rmse: 0.298754\tvalid_1's rmse: 0.320245\n",
      "[800]\ttraining's rmse: 0.29188\tvalid_1's rmse: 0.319989\n",
      "[1000]\ttraining's rmse: 0.286081\tvalid_1's rmse: 0.319882\n",
      "[1200]\ttraining's rmse: 0.280975\tvalid_1's rmse: 0.319889\n",
      "[1400]\ttraining's rmse: 0.27628\tvalid_1's rmse: 0.32009\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttraining's rmse: 0.285382\tvalid_1's rmse: 0.319839\n",
      "LGB 1--------------------------------------------------\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\ttraining's rmse: 0.31945\tvalid_1's rmse: 0.326898\n",
      "[400]\ttraining's rmse: 0.307656\tvalid_1's rmse: 0.321935\n",
      "[600]\ttraining's rmse: 0.29944\tvalid_1's rmse: 0.320243\n",
      "[800]\ttraining's rmse: 0.292708\tvalid_1's rmse: 0.31958\n",
      "[1000]\ttraining's rmse: 0.28705\tvalid_1's rmse: 0.319299\n",
      "[1200]\ttraining's rmse: 0.28193\tvalid_1's rmse: 0.319238\n",
      "[1400]\ttraining's rmse: 0.277321\tvalid_1's rmse: 0.319239\n",
      "[1600]\ttraining's rmse: 0.272942\tvalid_1's rmse: 0.319303\n",
      "Early stopping, best iteration is:\n",
      "[1141]\ttraining's rmse: 0.283378\tvalid_1's rmse: 0.319198\n",
      "LGB 2--------------------------------------------------\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\ttraining's rmse: 0.319156\tvalid_1's rmse: 0.327608\n",
      "[400]\ttraining's rmse: 0.307031\tvalid_1's rmse: 0.323287\n",
      "[600]\ttraining's rmse: 0.298585\tvalid_1's rmse: 0.322185\n",
      "[800]\ttraining's rmse: 0.291863\tvalid_1's rmse: 0.321766\n",
      "[1000]\ttraining's rmse: 0.286089\tvalid_1's rmse: 0.321695\n",
      "[1200]\ttraining's rmse: 0.281039\tvalid_1's rmse: 0.321827\n",
      "[1400]\ttraining's rmse: 0.276343\tvalid_1's rmse: 0.321935\n",
      "Early stopping, best iteration is:\n",
      "[909]\ttraining's rmse: 0.288619\tvalid_1's rmse: 0.32165\n",
      "LGB 3--------------------------------------------------\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\ttraining's rmse: 0.319763\tvalid_1's rmse: 0.3244\n",
      "[400]\ttraining's rmse: 0.307674\tvalid_1's rmse: 0.319923\n",
      "[600]\ttraining's rmse: 0.299238\tvalid_1's rmse: 0.318613\n",
      "[800]\ttraining's rmse: 0.29237\tvalid_1's rmse: 0.318306\n",
      "[1000]\ttraining's rmse: 0.286516\tvalid_1's rmse: 0.318258\n",
      "[1200]\ttraining's rmse: 0.281288\tvalid_1's rmse: 0.318287\n",
      "[1400]\ttraining's rmse: 0.276475\tvalid_1's rmse: 0.318432\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's rmse: 0.284459\tvalid_1's rmse: 0.318211\n",
      "LGB 4--------------------------------------------------\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\ttraining's rmse: 0.317242\tvalid_1's rmse: 0.33478\n",
      "[400]\ttraining's rmse: 0.305166\tvalid_1's rmse: 0.330835\n",
      "[600]\ttraining's rmse: 0.296821\tvalid_1's rmse: 0.329515\n",
      "[800]\ttraining's rmse: 0.290087\tvalid_1's rmse: 0.329087\n",
      "[1000]\ttraining's rmse: 0.284335\tvalid_1's rmse: 0.329007\n",
      "[1200]\ttraining's rmse: 0.279149\tvalid_1's rmse: 0.32896\n",
      "[1400]\ttraining's rmse: 0.274298\tvalid_1's rmse: 0.328981\n",
      "[1600]\ttraining's rmse: 0.269904\tvalid_1's rmse: 0.329128\n",
      "Early stopping, best iteration is:\n",
      "[1182]\ttraining's rmse: 0.279585\tvalid_1's rmse: 0.328943\n",
      "\n",
      "----------------------------------\n",
      "LightGBM\n",
      "----------------------------------\n",
      "FPR: 0.9109919571045576\n",
      "TPR: 0.9918622255866768\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "lgb_params = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "FOLDs = KFold(n_splits=5, shuffle=True, random_state=1989)\n",
    "\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros(len(X_test))\n",
    "\n",
    "features_lgb = list(X_train.columns)\n",
    "feature_importance_df_lgb = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(FOLDs.split(X_train)):\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "\n",
    "    print(\"LGB \" + str(fold_) + \"-\" * 50)\n",
    "    num_round = 2000\n",
    "    clf = lgb.train(lgb_params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 500)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df_lgb = pd.DataFrame()\n",
    "    fold_importance_df_lgb[\"feature\"] = features_lgb\n",
    "    fold_importance_df_lgb[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df_lgb[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df_lgb = pd.concat([feature_importance_df_lgb, fold_importance_df_lgb], axis=0)\n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / FOLDs.n_splits\n",
    "    \n",
    "# Test performance - FPR and TPR\n",
    "fpr_lgb, tpr_lgb = tpr_fpr(y_test, np.round(predictions_lgb))\n",
    "\n",
    "print(\"\\n----------------------------------\\nLightGBM\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_lgb)\n",
    "print(\"TPR:\", tpr_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section21'></a>\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 0--------------------------------------------------\n",
      "[0]\ttrain-rmse:0.499704\tvalid-rmse:0.499717\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 10 rounds.\n",
      "[200]\ttrain-rmse:0.447687\tvalid-rmse:0.450048\n",
      "[400]\ttrain-rmse:0.408104\tvalid-rmse:0.413104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ad60846001bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xgb \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moof_xgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1021\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.001, 'max_depth': 7, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True}\n",
    "\n",
    "FOLDs = KFold(n_splits=5, shuffle=True, random_state=1989)\n",
    "\n",
    "oof_xgb = np.zeros(len(X_train))\n",
    "predictions_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(FOLDs.split(X_train)):\n",
    "    trn_data = xgb.DMatrix(data=X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(data=X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    print(\"xgb \" + str(fold_) + \"-\" * 50)\n",
    "    num_round = 2000\n",
    "    xgb_model = xgb.train(xgb_params, trn_data, num_round, watchlist, early_stopping_rounds=10, verbose_eval=200)\n",
    "    oof_xgb[val_idx] = xgb_model.predict(xgb.DMatrix(X_train.iloc[val_idx]), ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "\n",
    "    predictions_xgb += xgb_model.predict(xgb.DMatrix(X_test), ntree_limit=xgb_model.best_ntree_limit+50) / FOLDs.n_splits\n",
    "    \n",
    "    \n",
    "# Test performance - FPR and TPR\n",
    "fpr_xgb, tpr_xgb = tpr_fpr(y_test, np.round(predictions_xgb))\n",
    "\n",
    "print(\"\\n----------------------------------\\nXGBoost\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_xgb)\n",
    "print(\"TPR:\", tpr_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section30'></a>\n",
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance - FPR and TPR (Ensemble)\n",
    "fpr_ens, tpr_ens = tpr_fpr(y_test, np.round(0.5*predictions_lgb + 0.5*predictions_xgb))\n",
    "\n",
    "print(\"\\n----------------------------------\\nEnsemble\\n----------------------------------\")\n",
    "print(\"FPR:\", fpr_ens)\n",
    "print(\"TPR:\", tpr_ens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section22'></a>\n",
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cols = (feature_importance_df_lgb[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df_lgb.loc[feature_importance_df_lgb.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section23'></a>\n",
    "# Conclusions\n",
    "It looks like the last model is still weighting too heavily on the 1 class, and mostly predicting ones. However, we've tested the performance of difference models and seen the effect of tweaking the penalties for LR and RF.\n",
    "\n",
    "If we take other approaches to handle the class imbalance and achieve a more balanced dataset to test the models, the quality of the observations will improve and we could get a more accurate value of TPR and FPR.\n",
    "\n",
    "As a conclusion, for a conservative investor, given that the model returned a certain TPR and FPR (say 9% FPR and 10% TPR, like the Logistic Regression model previously tested), it means that he/she will make money as long as the interest rate is high enough to offset the losses from 9% of borrowers defaulting, and that the pool of 10% of borrowers is large enough to make enough interest money to offset the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
